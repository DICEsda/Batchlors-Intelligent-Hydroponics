{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Digital Twins Integration\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Connect to Azure Digital Twins\n",
    "2. Query twins and relationships\n",
    "3. Update twins with ML predictions\n",
    "4. Build an end-to-end ML pipeline with ADT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/app/src')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ML imports\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Our custom connectors\n",
    "from data.adt_connector import AzureDigitalTwinsConnector, TwinState\n",
    "from data.mongodb_connector import MongoDBConnector\n",
    "from config import config\n",
    "\n",
    "print(\"Imports loaded successfully!\")\n",
    "print(f\"ADT Endpoint configured: {config.azure_dt.is_configured}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check configuration\n",
    "if not config.azure_dt.is_configured:\n",
    "    print(\"Azure Digital Twins is not configured!\")\n",
    "    print(\"Set AZURE_DT_ENDPOINT environment variable to your ADT instance URL.\")\n",
    "    print(\"Example: https://your-instance.api.westeurope.digitaltwins.azure.net\")\n",
    "    print(\"\\nFor authentication, you can use:\")\n",
    "    print(\"  1. Azure CLI: az login\")\n",
    "    print(\"  2. Managed Identity (in Azure)\")\n",
    "    print(\"  3. Service Principal: Set AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET\")\n",
    "else:\n",
    "    print(f\"ADT Endpoint: {config.azure_dt.endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Azure Digital Twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ADT connector\n",
    "# This will use DefaultAzureCredential (Azure CLI, Managed Identity, etc.)\n",
    "adt = AzureDigitalTwinsConnector()\n",
    "\n",
    "try:\n",
    "    adt.connect()\n",
    "    print(\"Successfully connected to Azure Digital Twins!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Check AZURE_DT_ENDPOINT is correct\")\n",
    "    print(\"  2. Run 'az login' if using Azure CLI credentials\")\n",
    "    print(\"  3. Ensure you have 'Azure Digital Twins Data Reader' role\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all coordinators\n",
    "coordinators = adt.get_all_coordinators()\n",
    "print(f\"Found {len(coordinators)} coordinators:\")\n",
    "\n",
    "for coord in coordinators:\n",
    "    print(f\"  - {coord.twin_id}\")\n",
    "    print(f\"    Status: {coord.properties.get('status', 'unknown')}\")\n",
    "    print(f\"    Towers online: {coord.properties.get('towers_online', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all towers\n",
    "towers = adt.get_all_towers()\n",
    "print(f\"Found {len(towers)} towers:\")\n",
    "\n",
    "for tower in towers:\n",
    "    print(f\"  - {tower.twin_id}\")\n",
    "    print(f\"    Crop: {tower.properties.get('crop_type', 'unknown')}\")\n",
    "    print(f\"    Status: {tower.properties.get('status', 'unknown')}\")\n",
    "    \n",
    "    reported = tower.properties.get('reported_state', {})\n",
    "    if reported:\n",
    "        print(f\"    Temp: {reported.get('air_temp_c', 'N/A')}°C\")\n",
    "        print(f\"    Humidity: {reported.get('humidity_pct', 'N/A')}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get twins as DataFrame for analysis\n",
    "twins_df = adt.get_all_twins_as_dataframe()\n",
    "\n",
    "if not twins_df.empty:\n",
    "    print(f\"Retrieved {len(twins_df)} twins\")\n",
    "    display(twins_df.head())\n",
    "else:\n",
    "    print(\"No twins found in ADT instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom query - find towers with specific conditions\n",
    "query = \"\"\"\n",
    "SELECT tower \n",
    "FROM digitaltwins tower\n",
    "WHERE IS_OF_MODEL('dtmi:iot:hydroponics:Tower;1')\n",
    "AND tower.status = 'operational'\n",
    "\"\"\"\n",
    "\n",
    "operational_towers = adt.query_twins(query)\n",
    "print(f\"Found {len(operational_towers)} operational towers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Relationships (Twin Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get towers connected to a specific coordinator\n",
    "if coordinators:\n",
    "    coord_id = coordinators[0].twin_id.replace('coordinator-', '')\n",
    "    coord_towers = adt.get_towers_by_coordinator(coord_id)\n",
    "    \n",
    "    print(f\"Towers connected to {coordinators[0].twin_id}:\")\n",
    "    for tower in coord_towers:\n",
    "        print(f\"  - {tower.twin_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relationships from a coordinator\n",
    "if coordinators:\n",
    "    relationships = adt.get_relationships(coordinators[0].twin_id)\n",
    "    \n",
    "    print(f\"Relationships from {coordinators[0].twin_id}:\")\n",
    "    for rel in relationships:\n",
    "        print(f\"  -{rel.relationship_name}-> {rel.target_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ML Pipeline with ADT\n",
    "\n",
    "Example: Train a growth prediction model using MongoDB historical data, then push predictions to ADT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get historical data from MongoDB\n",
    "mongo = MongoDBConnector()\n",
    "\n",
    "# Get height measurements for training\n",
    "height_df = mongo.get_height_measurements()\n",
    "\n",
    "if height_df.empty:\n",
    "    print(\"No height data available. Creating synthetic data for demo...\")\n",
    "    # Create synthetic data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    height_df = pd.DataFrame({\n",
    "        'tower_id': [f'tower-{i % 5}' for i in range(n_samples)],\n",
    "        'days_since_planting': np.random.randint(1, 60, n_samples),\n",
    "        'height_cm': None,  # Will be calculated\n",
    "        'crop_type': np.random.choice(['Lettuce', 'Basil', 'Spinach'], n_samples),\n",
    "    })\n",
    "    # Simulate growth: height = base + growth_rate * days + noise\n",
    "    height_df['height_cm'] = 2 + 0.5 * height_df['days_since_planting'] + np.random.randn(n_samples) * 2\n",
    "    height_df['height_cm'] = height_df['height_cm'].clip(lower=0)\n",
    "\n",
    "print(f\"Training data: {len(height_df)} samples\")\n",
    "display(height_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train a growth prediction model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features\n",
    "X = height_df[['days_since_planting']].values\n",
    "y = height_df['height_cm'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model trained!\")\n",
    "print(f\"  Train R²: {train_score:.3f}\")\n",
    "print(f\"  Test R²: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate predictions for each tower in ADT\n",
    "def predict_for_tower(tower: TwinState) -> dict:\n",
    "    \"\"\"Generate ML predictions for a tower.\"\"\"\n",
    "    # Get current state\n",
    "    growth = tower.properties.get('growth_tracking', {})\n",
    "    days_planted = growth.get('days_since_planting', 0)\n",
    "    current_height = growth.get('last_height_cm', 0)\n",
    "    \n",
    "    # Predict future height (7 days from now)\n",
    "    future_days = days_planted + 7\n",
    "    predicted_height = model.predict([[future_days]])[0]\n",
    "    \n",
    "    # Estimate growth rate\n",
    "    if days_planted > 0:\n",
    "        growth_rate = current_height / days_planted\n",
    "    else:\n",
    "        growth_rate = 0.5  # Default estimate\n",
    "    \n",
    "    # Estimate harvest date (assume harvest at 30cm for lettuce)\n",
    "    target_height = 30\n",
    "    if growth_rate > 0 and current_height < target_height:\n",
    "        days_to_harvest = int((target_height - current_height) / growth_rate)\n",
    "    else:\n",
    "        days_to_harvest = 0\n",
    "    \n",
    "    return {\n",
    "        'predicted_height_cm': round(predicted_height, 1),\n",
    "        'growth_rate_cm_per_day': round(growth_rate, 2),\n",
    "        'days_to_harvest': max(0, days_to_harvest),\n",
    "        'health_score': 0.85,  # Placeholder - would use anomaly detection\n",
    "    }\n",
    "\n",
    "# Generate predictions for all towers\n",
    "predictions = {}\n",
    "for tower in towers:\n",
    "    preds = predict_for_tower(tower)\n",
    "    predictions[tower.twin_id] = preds\n",
    "    print(f\"{tower.twin_id}: height={preds['predicted_height_cm']}cm, harvest in {preds['days_to_harvest']} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Push predictions to Azure Digital Twins\n",
    "if predictions:\n",
    "    results = adt.batch_update_predictions(\n",
    "        predictions=predictions,\n",
    "        model_name=\"growth_predictor\",\n",
    "        model_version=\"1.0.0\"\n",
    "    )\n",
    "    \n",
    "    success_count = sum(results.values())\n",
    "    print(f\"\\nUpdated {success_count}/{len(predictions)} twins with ML predictions\")\n",
    "else:\n",
    "    print(\"No towers to update.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Anomaly Detection & Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an anomaly detection model on telemetry data\n",
    "tower_telemetry = mongo.get_tower_telemetry(hours=168)  # Last week\n",
    "\n",
    "if tower_telemetry.empty:\n",
    "    print(\"No telemetry data. Creating synthetic data for demo...\")\n",
    "    np.random.seed(42)\n",
    "    n = 200\n",
    "    tower_telemetry = pd.DataFrame({\n",
    "        'air_temp_c': np.random.normal(24, 2, n),\n",
    "        'humidity_pct': np.random.normal(65, 5, n),\n",
    "    })\n",
    "    # Add some anomalies\n",
    "    tower_telemetry.loc[190:195, 'air_temp_c'] = 40  # Temperature spike\n",
    "    tower_telemetry.loc[196:199, 'humidity_pct'] = 10  # Humidity drop\n",
    "\n",
    "# Train Isolation Forest\n",
    "features = ['air_temp_c', 'humidity_pct']\n",
    "available_features = [f for f in features if f in tower_telemetry.columns]\n",
    "\n",
    "if available_features:\n",
    "    X = tower_telemetry[available_features].dropna()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    iso_forest.fit(X_scaled)\n",
    "    \n",
    "    print(f\"Anomaly detection model trained on {len(X)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each tower's current state for anomalies\n",
    "def check_tower_anomaly(tower: TwinState) -> float:\n",
    "    \"\"\"Calculate anomaly score for a tower's current state.\"\"\"\n",
    "    reported = tower.properties.get('reported_state', {})\n",
    "    \n",
    "    if not reported:\n",
    "        return 0.0\n",
    "    \n",
    "    # Extract features\n",
    "    temp = reported.get('air_temp_c')\n",
    "    humidity = reported.get('humidity_pct')\n",
    "    \n",
    "    if temp is None or humidity is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Scale and predict\n",
    "    X_current = scaler.transform([[temp, humidity]])\n",
    "    score = iso_forest.decision_function(X_current)[0]\n",
    "    \n",
    "    # Convert to 0-1 scale (higher = more anomalous)\n",
    "    anomaly_score = max(0, -score)  # Negative scores indicate anomalies\n",
    "    return min(1.0, anomaly_score)\n",
    "\n",
    "# Check all towers\n",
    "for tower in towers:\n",
    "    score = check_tower_anomaly(tower)\n",
    "    status = \"ALERT\" if score > 0.5 else \"OK\"\n",
    "    print(f\"{tower.twin_id}: anomaly_score={score:.2f} [{status}]\")\n",
    "    \n",
    "    # Update ADT with anomaly score\n",
    "    if score > 0:\n",
    "        adt.update_ml_predictions(\n",
    "            tower.twin_id,\n",
    "            {'anomaly_score': round(score, 3)},\n",
    "            model_name=\"anomaly_detector\",\n",
    "            model_version=\"1.0.0\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Query ADT for ML Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find towers that need attention (high anomaly scores)\n",
    "towers_needing_attention = adt.get_towers_needing_attention(anomaly_threshold=0.3)\n",
    "\n",
    "print(f\"Towers needing attention: {len(towers_needing_attention)}\")\n",
    "for tower in towers_needing_attention:\n",
    "    ml_preds = tower.properties.get('ml_predictions', {})\n",
    "    print(f\"  - {tower.twin_id}\")\n",
    "    print(f\"    Anomaly score: {ml_preds.get('anomaly_score', 'N/A')}\")\n",
    "    print(f\"    Generated at: {ml_preds.get('generated_at', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom query: Find towers ready for harvest\n",
    "harvest_query = \"\"\"\n",
    "SELECT tower\n",
    "FROM digitaltwins tower\n",
    "WHERE IS_OF_MODEL('dtmi:iot:hydroponics:Tower;1')\n",
    "AND tower.ml_predictions.days_to_harvest <= 7\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    ready_for_harvest = adt.query_twins(harvest_query)\n",
    "    print(f\"Towers ready for harvest within 7 days: {len(ready_for_harvest)}\")\n",
    "    for tower in ready_for_harvest:\n",
    "        ml_preds = tower.properties.get('ml_predictions', {})\n",
    "        print(f\"  - {tower.twin_id}: {ml_preds.get('days_to_harvest', 'N/A')} days\")\n",
    "except Exception as e:\n",
    "    print(f\"Query failed (may not have ml_predictions yet): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Upload DTDL Models (One-time Setup)\n",
    "\n",
    "Run this section once to upload the DTDL models to your ADT instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def upload_dtdl_models(adt_connector: AzureDigitalTwinsConnector, models_dir: str):\n",
    "    \"\"\"Upload DTDL models to Azure Digital Twins.\"\"\"\n",
    "    models_path = Path(models_dir)\n",
    "    \n",
    "    # Order matters - upload dependencies first\n",
    "    model_order = ['Farm.json', 'Reservoir.json', 'Tower.json', 'Coordinator.json']\n",
    "    \n",
    "    models = []\n",
    "    for model_file in model_order:\n",
    "        file_path = models_path / model_file\n",
    "        if file_path.exists():\n",
    "            with open(file_path) as f:\n",
    "                models.append(json.load(f))\n",
    "            print(f\"Loaded: {model_file}\")\n",
    "    \n",
    "    if models:\n",
    "        try:\n",
    "            adt_connector.client.create_models(models)\n",
    "            print(f\"\\nSuccessfully uploaded {len(models)} models to ADT!\")\n",
    "        except Exception as e:\n",
    "            if \"already exists\" in str(e).lower():\n",
    "                print(\"Models already exist in ADT (this is OK).\")\n",
    "            else:\n",
    "                print(f\"Error uploading models: {e}\")\n",
    "\n",
    "# Uncomment to upload models\n",
    "# upload_dtdl_models(adt, '/app/models/dtdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo.close()\n",
    "print(\"Connections closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Set up ADT instance** in Azure Portal\n",
    "2. **Upload DTDL models** using the cell above\n",
    "3. **Create twins** for your coordinators, towers, and reservoirs\n",
    "4. **Set up IoT Hub** to route telemetry to ADT\n",
    "5. **Schedule ML jobs** to periodically update predictions\n",
    "\n",
    "### Architecture with ADT:\n",
    "\n",
    "```\n",
    "┌─────────────┐    ┌─────────────┐    ┌─────────────────────┐\n",
    "│  ESP32      │───>│  IoT Hub    │───>│  Azure Digital Twins│\n",
    "│  Devices    │    │  (Telemetry)│    │  (Twin State)       │\n",
    "└─────────────┘    └─────────────┘    └──────────┬──────────┘\n",
    "                                                 │\n",
    "                   ┌─────────────┐               │\n",
    "                   │  MongoDB    │<──────────────┤ (Historical)\n",
    "                   │  (History)  │               │\n",
    "                   └──────┬──────┘               │\n",
    "                          │                      │\n",
    "                   ┌──────▼──────┐               │\n",
    "                   │  ML Service │───────────────┘ (Predictions)\n",
    "                   │  (This!)    │\n",
    "                   └─────────────┘\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
